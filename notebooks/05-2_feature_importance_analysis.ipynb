{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2236196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import shap\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Enhanced Academic publication style settings\n",
    "plt.style.use('seaborn-v0_8-paper')\n",
    "sns.set_context(\"paper\", font_scale=1.6)\n",
    "sns.set_palette(\"deep\")\n",
    "\n",
    "# Configure matplotlib for publication quality with BOLD and BIGGER fonts\n",
    "plt.rcParams['figure.figsize'] = (14, 7)\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman', 'DejaVu Serif']\n",
    "plt.rcParams['font.size'] = 13\n",
    "plt.rcParams['axes.labelsize'] = 15\n",
    "plt.rcParams['axes.titlesize'] = 17\n",
    "plt.rcParams['axes.titleweight'] = 'bold'\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['xtick.labelsize'] = 13\n",
    "plt.rcParams['ytick.labelsize'] = 13\n",
    "plt.rcParams['legend.fontsize'] = 12\n",
    "plt.rcParams['legend.frameon'] = True\n",
    "plt.rcParams['legend.edgecolor'] = 'black'\n",
    "plt.rcParams['legend.title_fontsize'] = 13\n",
    "plt.rcParams['axes.linewidth'] = 1.5\n",
    "plt.rcParams['grid.alpha'] = 0.3\n",
    "plt.rcParams['grid.linestyle'] = '--'\n",
    "plt.rcParams['xtick.major.width'] = 1.2\n",
    "plt.rcParams['ytick.major.width'] = 1.2\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")\n",
    "print(\"Enhanced academic publication style configured\")\n",
    "print(\"Experiment 2: WITH Artist Features (414 features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815370e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths for Experiment 2\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "FEATURES_DIR = PROJECT_ROOT / \"features\"\n",
    "MODELS_DIR = PROJECT_ROOT / \"models\" / \"saved\" / \"experiment2_with_artist\"\n",
    "RESULTS_DIR = PROJECT_ROOT / \"results\" / \"metrics\" / \"experiment2_with_artist\"\n",
    "FIGURES_DIR = PROJECT_ROOT / \"results\" / \"figures\"\n",
    "\n",
    "# Create directories\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Configuration - Top models per target for Experiment 2\n",
    "TOP_MODELS = {\n",
    "    'valence': 'XGBoost_tuned',\n",
    "    'energy': 'XGBoost_tuned',\n",
    "    'danceability': 'CatBoost',\n",
    "    'popularity': 'CatBoost_tuned'\n",
    "}\n",
    "\n",
    "TARGETS = list(TOP_MODELS.keys())\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Experiment 2: WITH Artist Features\")\n",
    "print(f\"Targets and their top models:\")\n",
    "for target, model in TOP_MODELS.items():\n",
    "    print(f\"   - {target:12s}: {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60645de0",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ“‹ Load Feature Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874ec4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_feature_names():\n",
    "    \"\"\"Load feature names from metadata with proper audio feature names\"\"\"\n",
    "    feature_names = []\n",
    "    \n",
    "    # Audio features (23 for Experiment 2 - includes 2 artist features)\n",
    "    audio_names_path = FEATURES_DIR / \"audio_feature_names.txt\"\n",
    "    if audio_names_path.exists():\n",
    "        with open(audio_names_path, 'r') as f:\n",
    "            audio_features = [line.strip() for line in f \n",
    "                            if line.strip() and not line.strip().startswith('#')]\n",
    "        feature_names.extend(audio_features)\n",
    "        print(f\"Loaded {len(audio_features)} audio features from file\")\n",
    "    else:\n",
    "        # Fallback: use standard Spotify audio feature names\n",
    "        audio_features = [\n",
    "            'danceability', 'energy', 'loudness', 'speechiness', \n",
    "            'acousticness', 'instrumentalness', 'liveness', 'tempo',\n",
    "            'genre_Rock', 'genre_Pop', 'genre_Hip-Hop', 'genre_Electronic',\n",
    "            'genre_Jazz', 'genre_Classical', 'genre_Country', 'genre_R&B',\n",
    "            'genre_Indie', 'genre_Metal', 'year_normalized', 'mode',\n",
    "            'key_sin', 'log_total_artist_followers', 'avg_artist_popularity'\n",
    "        ]\n",
    "        feature_names.extend(audio_features)\n",
    "        print(f\"Audio feature file not found, using default names\")\n",
    "    \n",
    "    # Text stats (5)\n",
    "    text_stats = ['word_count', 'unique_word_count', 'unique_ratio', 'avg_word_length', 'char_count']\n",
    "    feature_names.extend(text_stats)\n",
    "    \n",
    "    # Sentiment (2)\n",
    "    sentiment = ['sentiment_polarity', 'sentiment_subjectivity']\n",
    "    feature_names.extend(sentiment)\n",
    "    \n",
    "    # Embeddings (384)\n",
    "    embedding_names = [f'emb_{i}' for i in range(384)]\n",
    "    feature_names.extend(embedding_names)\n",
    "    \n",
    "    return feature_names\n",
    "\n",
    "feature_names = load_feature_names()\n",
    "print(f\"Total features loaded: {len(feature_names)}\")\n",
    "print(f\"\\nFirst 32 features (including artist features):\")\n",
    "for i, name in enumerate(feature_names[:32]):\n",
    "    print(f\" {i:3d}. {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59217954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_validation_data():\n",
    "    \"\"\"Load validation features and targets from .npy files (Experiment 2)\"\"\"\n",
    "    try:\n",
    "        # Load feature components (23 audio features including artist)\n",
    "        X_audio = np.load(FEATURES_DIR / \"X_val_audio.npy\")\n",
    "        X_text_stats = np.load(FEATURES_DIR / \"X_val_text_stats.npy\")\n",
    "        X_sentiment = np.load(FEATURES_DIR / \"X_val_sentiment.npy\")\n",
    "        X_embeddings = np.load(FEATURES_DIR / \"X_val_embeddings.npy\")\n",
    "        \n",
    "        # Concatenate features (23 + 5 + 2 + 384 = 414)\n",
    "        X_val_arr = np.hstack([X_audio, X_text_stats, X_sentiment, X_embeddings])\n",
    "        \n",
    "        # Create DataFrame\n",
    "        X_val = pd.DataFrame(X_val_arr, columns=feature_names)\n",
    "        \n",
    "        # Load targets\n",
    "        y_val = pd.DataFrame({\n",
    "            'valence': np.load(FEATURES_DIR / \"y_val_valence.npy\"),\n",
    "            'energy': np.load(FEATURES_DIR / \"y_val_energy.npy\"),\n",
    "            'danceability': np.load(FEATURES_DIR / \"y_val_danceability.npy\"),\n",
    "            'popularity': np.load(FEATURES_DIR / \"y_val_popularity.npy\")\n",
    "        })\n",
    "        \n",
    "        return X_val, y_val\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading validation data: {e}\")\n",
    "        return None, None\n",
    "\n",
    "X_val, y_val = load_validation_data()\n",
    "if X_val is not None:\n",
    "    print(f\"Loaded Experiment 2 validation data: {X_val.shape}\")\n",
    "    print(f\"Targets shape: {y_val.shape}\")\n",
    "    print(f\"Features: 23 audio (incl. artist) + 5 text + 2 sentiment + 384 embeddings = 414 total\")\n",
    "else:\n",
    "    print(\"Failed to load validation data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594993d7",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ”§ Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4421b444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance(model, model_name, feature_names):\n",
    "    \"\"\"Extract feature importance from a model\"\"\"\n",
    "    \n",
    "    importance = None\n",
    "    method = None\n",
    "    \n",
    "    # Tree-based models with feature_importances_\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importance = model.feature_importances_\n",
    "        method = 'feature_importances_'\n",
    "    \n",
    "    # MLPRegressor - use first layer weights\n",
    "    elif hasattr(model, 'coefs_') and len(model.coefs_) > 0:\n",
    "        # Sum absolute weights from input to first hidden layer\n",
    "        first_layer_weights = model.coefs_[0]\n",
    "        importance = np.abs(first_layer_weights).sum(axis=1)\n",
    "        method = 'mlp_first_layer'\n",
    "    \n",
    "    # Linear models with coef_\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        importance = np.abs(model.coef_)\n",
    "        if importance.ndim > 1:\n",
    "            importance = importance.mean(axis=0)\n",
    "        method = 'coef_'\n",
    "    \n",
    "    if importance is not None:\n",
    "        # Verify shape\n",
    "        if len(importance) != len(feature_names):\n",
    "            print(f\"Shape mismatch: {len(importance)} vs {len(feature_names)}\")\n",
    "            return None\n",
    "        \n",
    "        # Normalize\n",
    "        if importance.sum() > 0:\n",
    "            importance = importance / importance.sum()\n",
    "        \n",
    "        return pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': importance,\n",
    "            'method': method\n",
    "        }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def analyze_model_importance(target, model_name, feature_names):\n",
    "    \"\"\"Analyze feature importance for a specific model and target\"\"\"\n",
    "    \n",
    "    model_path = MODELS_DIR / f\"{model_name}_{target}.pkl\"\n",
    "    \n",
    "    if not model_path.exists():\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        model = joblib.load(model_path)\n",
    "        importance_df = get_feature_importance(model, model_name, feature_names)\n",
    "        \n",
    "        if importance_df is not None:\n",
    "            importance_df['target'] = target\n",
    "            importance_df['model'] = model_name\n",
    "            return importance_df\n",
    "        return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {model_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276ec587",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸš€ Extract Feature Importance from All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d5be8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracting feature importance for top models...\\n\")\n",
    "\n",
    "all_importance = []\n",
    "\n",
    "for target, model_name in TOP_MODELS.items():\n",
    "    print(f\"{target.upper()} (Model: {model_name})\")\n",
    "    \n",
    "    result = analyze_model_importance(target, model_name, feature_names)\n",
    "    if result is not None:\n",
    "        all_importance.append(result)\n",
    "        top_feat = result.iloc[0]['feature']\n",
    "        top_imp = result.iloc[0]['importance']\n",
    "        print(f\"   Success â†’ Top feature: {top_feat} ({top_imp:.3f})\")\n",
    "    else:\n",
    "        print(f\"   Failed to load or analyze\")\n",
    "\n",
    "# Combine all results\n",
    "if all_importance:\n",
    "    all_importance_df = pd.concat(all_importance, ignore_index=True)\n",
    "    print(f\"\\nExtracted importance for {len(all_importance)} top models\")\n",
    "else:\n",
    "    print(\"\\nNo importance data extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530daa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save raw data\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "raw_path = RESULTS_DIR / f\"feature_importance_raw_{timestamp}.csv\"\n",
    "\n",
    "print(f\"Saving to: {raw_path}\")\n",
    "print(f\"DataFrame shape: {all_importance_df.shape}\")\n",
    "print(f\"Directory exists: {RESULTS_DIR.exists()}\")\n",
    "\n",
    "all_importance_df.to_csv(raw_path, index=False)\n",
    "\n",
    "# Verify file was saved\n",
    "if raw_path.exists():\n",
    "    file_size = raw_path.stat().st_size / 1024\n",
    "    print(f\"Saved raw importance data: {raw_path.name} ({file_size:.1f} KB)\")\n",
    "else:\n",
    "    print(f\"ERROR: File was not saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f8a13e",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ“Š Top 20 Features per Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bed7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TOP 20 FEATURES PER TARGET (averaged across models)\\n\")\n",
    "\n",
    "summary_data = []\n",
    "\n",
    "for target in TARGETS:\n",
    "    target_df = all_importance_df[all_importance_df['target'] == target]\n",
    "    top20 = target_df.groupby('feature')['importance'].mean().nlargest(20)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"{target.upper()}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    for i, (feat, imp) in enumerate(top20.items(), 1):\n",
    "        print(f\"   {i:2d}. {feat:<30s} {imp:.4f}\")\n",
    "        summary_data.append({\n",
    "            'target': target,\n",
    "            'rank': i,\n",
    "            'feature': feat,\n",
    "            'avg_importance': imp\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_path = RESULTS_DIR / f\"feature_importance_summary_{timestamp}.csv\"\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "print(f\"\\nSaved summary: {summary_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c905517c",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ“ˆ Visualization 1: Top 20 Features per Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae9530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_features(all_importance, target, top_n=20):\n",
    "    \"\"\"Plot top N features for a target with enhanced academic styling\"\"\"\n",
    "    target_df = all_importance[all_importance['target'] == target].copy()\n",
    "    agg_importance = target_df.groupby('feature')['importance'].mean().sort_values(ascending=False)\n",
    "    top_features = agg_importance.head(top_n)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 9))\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(top_features)))\n",
    "    \n",
    "    bars = ax.barh(range(len(top_features)), top_features.values, \n",
    "                   color=colors, edgecolor='black', alpha=0.85, linewidth=1.5)\n",
    "    ax.set_yticks(range(len(top_features)))\n",
    "    ax.set_yticklabels(top_features.index, fontweight='bold', fontsize=12)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel('Average Importance', fontsize=15, fontweight='bold', labelpad=10)\n",
    "    ax.set_title(f'Experiment 2: Top {top_n} Features for {target.upper()}', \n",
    "                 fontsize=17, fontweight='bold', pad=20)\n",
    "    ax.grid(True, alpha=0.3, axis='x', linestyle='--', linewidth=1.2)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(1.5)\n",
    "    ax.spines['bottom'].set_linewidth(1.5)\n",
    "    ax.tick_params(axis='both', width=1.2)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, val in zip(bars, top_features.values):\n",
    "        ax.text(val + 0.001, bar.get_y() + bar.get_height()/2, \n",
    "                f'{val:.3f}', va='center', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Generate plots for all targets\n",
    "for target in TARGETS:\n",
    "    fig = plot_top_features(all_importance_df, target, top_n=20)\n",
    "    fig_path = FIGURES_DIR / f\"experiment2_shap_feature_importance_{target}.png\"\n",
    "    fig.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Saved: {fig_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5d3f71",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ§  Explainable AI (XAI): SHAP Global Analysis\n",
    "SHAP (SHapley Additive exPlanations) provides a mathematically grounded way to explain model predictions. Unlike simple feature importance, SHAP shows the **direction** of the effect (e.g., does high energy increase or decrease valence?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d03bc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_shap_analysis(target, model_name, X_sample):\n",
    "    \"\"\"Run SHAP analysis for a specific model and target with enhanced styling\"\"\"\n",
    "    model_path = MODELS_DIR / f\"{model_name}_{target}.pkl\"\n",
    "    \n",
    "    if not model_path.exists():\n",
    "        print(f\"Model not found: {model_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Running SHAP for {target} ({model_name})...\")\n",
    "    model = joblib.load(model_path)\n",
    "    \n",
    "    # Create explainer\n",
    "    # For XGBoost and CatBoost, we can use TreeExplainer which is very fast\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_sample)\n",
    "    \n",
    "    # Plot Summary with enhanced styling\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    shap.summary_plot(shap_values, X_sample, show=False, plot_size=(14, 10), max_display=20)\n",
    "    plt.title(f\"SHAP - {target.upper()} ({model_name})\", \n",
    "              fontsize=17, fontweight='bold', pad=20)\n",
    "    # plt.xlabel('SHAP value (impact on model output)', fontsize=15, fontweight='bold')\n",
    "    plt.tick_params(axis='both', labelsize=12, width=1.2)\n",
    "    \n",
    "    fig_path = FIGURES_DIR / f\"experiment2_shap_summary_{target}.png\"\n",
    "    plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Saved SHAP summary: {fig_path.name}\")\n",
    "    \n",
    "    return shap_values\n",
    "\n",
    "# Use a sample of 500 instances for SHAP to keep it fast\n",
    "SHAP_SAMPLE_SIZE = 500\n",
    "X_shap_sample = X_val.sample(min(SHAP_SAMPLE_SIZE, len(X_val)), random_state=42)\n",
    "\n",
    "shap_results = {}\n",
    "for target, model_name in TOP_MODELS.items():\n",
    "    shap_val = run_shap_analysis(target, model_name, X_shap_sample)\n",
    "    shap_results[target] = shap_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5bbf50",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ” Explainable AI (XAI): LIME Local Analysis\n",
    "LIME (Local Interpretable Model-agnostic Explanations) helps us understand **why** the model made a specific prediction for a single song. It creates a local linear model around that specific instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfb631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lime_analysis(target, model_name, X_train_sample, X_test_instance, instance_idx):\n",
    "    \"\"\"Run LIME for a specific instance with enhanced styling\"\"\"\n",
    "    model_path = MODELS_DIR / f\"{model_name}_{target}.pkl\"\n",
    "    model = joblib.load(model_path)\n",
    "    \n",
    "    # Create LIME explainer\n",
    "    explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "        training_data=X_train_sample.values,\n",
    "        feature_names=X_train_sample.columns.tolist(),\n",
    "        class_names=[target],\n",
    "        mode='regression'\n",
    "    )\n",
    "    \n",
    "    # Explain prediction\n",
    "    exp = explainer.explain_instance(\n",
    "        X_test_instance.values, \n",
    "        model.predict, \n",
    "        num_features=10\n",
    "    )\n",
    "    \n",
    "    # Plot with enhanced styling\n",
    "    fig = exp.as_pyplot_figure()\n",
    "    fig.set_size_inches(14, 7)\n",
    "    plt.title(f\"Experiment 2: LIME Explanation - {target.upper()} (Instance {instance_idx})\", \n",
    "              fontsize=17, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Feature Contribution', fontsize=15, fontweight='bold')\n",
    "    plt.tick_params(axis='both', labelsize=12, width=1.2)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fig_path = FIGURES_DIR / f\"experiment2_lime_{target}_instance_{instance_idx}.png\"\n",
    "    plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return exp\n",
    "\n",
    "# Pick an instance to explain (e.g., the first one in our validation set)\n",
    "instance_to_explain = X_val.iloc[0]\n",
    "print(f\"Explaining prediction for first instance in validation set...\")\n",
    "\n",
    "for target, model_name in TOP_MODELS.items():\n",
    "    print(f\"\\nLIME for {target}...\")\n",
    "    run_lime_analysis(target, model_name, X_shap_sample, instance_to_explain, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d28433",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ“Š Visualization 2: Feature Group Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68ee1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_groups():\n",
    "    \"\"\"Define feature groups including artist features for Experiment 2\"\"\"\n",
    "    groups = {\n",
    "        'audio_continuous': list(range(0, 7)),   # acousticness, instrumentalness, speechiness, liveness, loudness, tempo, duration_ms\n",
    "        'year': [7],\n",
    "        'mode': [8],\n",
    "        'key_cyclical': [9, 10],  # key_sin, key_cos\n",
    "        'genre': list(range(11, 21)),  # 10 genre features (Blues, Classical, Country, Electronic, Folk, Hip-Hop, Jazz, Pop, R&B, Rock)\n",
    "        'artist': [21, 22],  # log_total_artist_followers + avg_artist_popularity\n",
    "        'text_stats': list(range(23, 28)),  # word_count, unique_word_count, unique_ratio, avg_word_length, char_count\n",
    "        'sentiment': list(range(28, 30)),  # sentiment_polarity, sentiment_subjectivity\n",
    "        'embeddings': list(range(30, 414)),  # 384 embedding features\n",
    "    }\n",
    "    return groups\n",
    "\n",
    "def aggregate_by_group(importance_df, feature_names):\n",
    "    \"\"\"Aggregate feature importance by group\"\"\"\n",
    "    groups = create_feature_groups()\n",
    "    group_importance = {}\n",
    "    \n",
    "    for group_name, indices in groups.items():\n",
    "        group_features = [feature_names[i] for i in indices if i < len(feature_names)]\n",
    "        mask = importance_df['feature'].isin(group_features)\n",
    "        group_importance[group_name] = importance_df.loc[mask, 'importance'].sum()\n",
    "    \n",
    "    return pd.Series(group_importance).sort_values(ascending=False)\n",
    "\n",
    "# Plot for Top Models with enhanced styling\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#28A745', '#6C757D', '#17A2B8', '#FFC107', '#FF69B4']\n",
    "\n",
    "for ax, target in zip(axes.flatten(), TARGETS):\n",
    "    model_name = TOP_MODELS[target]\n",
    "    target_df = all_importance_df[(all_importance_df['target'] == target) & (all_importance_df['model'] == model_name)]\n",
    "    \n",
    "    if target_df.empty:\n",
    "        ax.text(0.5, 0.5, f\"No data for {target}\", ha='center', fontsize=14, fontweight='bold')\n",
    "        continue\n",
    "        \n",
    "    group_imp = aggregate_by_group(target_df, feature_names)\n",
    "    avg_group = group_imp.sort_values(ascending=True)\n",
    "    \n",
    "    bars = ax.barh(range(len(avg_group)), avg_group.values, \n",
    "                  color=colors[:len(avg_group)], edgecolor='black', alpha=0.85, linewidth=1.5)\n",
    "    ax.set_yticks(range(len(avg_group)))\n",
    "    ax.set_yticklabels(avg_group.index, fontweight='bold', fontsize=12)\n",
    "    ax.set_xlabel('Importance', fontsize=14, fontweight='bold', labelpad=8)\n",
    "    ax.set_title(f'{target.upper()} ({model_name})', fontsize=15, fontweight='bold', pad=15)\n",
    "    ax.grid(True, alpha=0.3, axis='x', linestyle='--', linewidth=1.2)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(1.5)\n",
    "    ax.spines['bottom'].set_linewidth(1.5)\n",
    "    ax.tick_params(axis='both', width=1.2)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, val in zip(bars, avg_group.values):\n",
    "        ax.text(val + 0.005, bar.get_y() + bar.get_height()/2, \n",
    "                f'{val:.2%}', va='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Experiment 2: Feature Group Importance for Top Models (With Artist Features)', \n",
    "             fontsize=17, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "fig_path = FIGURES_DIR / \"experiment2_feature_group_importance_top_models.png\"\n",
    "plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"Saved: {fig_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51977e79",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ”‘ Key Insights: Embedding Contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780be8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"EMBEDDING CONTRIBUTION ANALYSIS\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "embedding_cols = [f'emb_{i}' for i in range(384)]\n",
    "\n",
    "insights = []\n",
    "for target in TARGETS:\n",
    "    target_df = all_importance_df[all_importance_df['target'] == target]\n",
    "    emb_importance = target_df[target_df['feature'].isin(embedding_cols)]['importance'].sum()\n",
    "    total_importance = target_df['importance'].sum()\n",
    "    emb_pct = (emb_importance / total_importance * 100) if total_importance > 0 else 0\n",
    "    \n",
    "    print(f\"   {target.upper():15s} â†’ Embeddings: {emb_pct:5.1f}% of total importance\")\n",
    "    insights.append({'target': target, 'embedding_contribution_pct': emb_pct})\n",
    "\n",
    "insights_df = pd.DataFrame(insights)\n",
    "display(insights_df.style.format({'embedding_contribution_pct': '{:.2f}%'}).background_gradient(\n",
    "    subset=['embedding_contribution_pct'], cmap='YlOrRd'\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
