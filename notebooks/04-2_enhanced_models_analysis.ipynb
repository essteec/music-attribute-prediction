{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98960245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Enhanced Academic publication style settings\n",
    "plt.style.use('seaborn-v0_8-paper')\n",
    "sns.set_context(\"paper\", font_scale=1.6)\n",
    "sns.set_palette(\"deep\")\n",
    "\n",
    "# Configure matplotlib for publication quality with BOLD and BIGGER fonts\n",
    "plt.rcParams['figure.figsize'] = (14, 7)\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman', 'DejaVu Serif']\n",
    "plt.rcParams['font.size'] = 13\n",
    "plt.rcParams['axes.labelsize'] = 15\n",
    "plt.rcParams['axes.titlesize'] = 17\n",
    "plt.rcParams['axes.titleweight'] = 'bold'\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['xtick.labelsize'] = 13\n",
    "plt.rcParams['ytick.labelsize'] = 13\n",
    "plt.rcParams['legend.fontsize'] = 12\n",
    "plt.rcParams['legend.frameon'] = True\n",
    "plt.rcParams['legend.edgecolor'] = 'black'\n",
    "plt.rcParams['legend.title_fontsize'] = 13\n",
    "plt.rcParams['axes.linewidth'] = 1.5\n",
    "plt.rcParams['grid.alpha'] = 0.3\n",
    "plt.rcParams['grid.linestyle'] = '--'\n",
    "plt.rcParams['xtick.major.width'] = 1.2\n",
    "plt.rcParams['ytick.major.width'] = 1.2\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")\n",
    "print(\"Enhanced academic publication style configured\")\n",
    "print(\"Experiment 2: WITH Artist Features (414 features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09111830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Experiment 2 results (with artist features)\n",
    "df_raw = pd.read_csv('../results/metrics/experiment2_with_artist/enhanced_results_detailed_20251231_143812.csv')\n",
    "\n",
    "# Filter to keep only specified models\n",
    "selected_models = [\n",
    "    'CatBoost', 'CatBoost_tuned',\n",
    "    'LightGBM', 'LightGBM_tuned',\n",
    "    'XGBoost', 'XGBoost_tuned',\n",
    "    'ExtraTrees', 'ExtraTrees_tuned',\n",
    "    'MLPRegressor', 'MLPRegressor_tuned',\n",
    "    'RandomForest', 'RandomForest_tuned'\n",
    "]\n",
    "\n",
    "df = df_raw[df_raw['model'].isin(selected_models)].copy()\n",
    "\n",
    "print(f\"Loaded {len(df_raw)} total model results from Experiment 2\")\n",
    "print(f\"Filtered to {len(df)} results ({len(selected_models)} models)\")\n",
    "print(f\"Targets: {df['target'].unique().tolist()}\")\n",
    "print(f\"Selected Models: {sorted(df['model'].unique().tolist())}\")\n",
    "print(f\"Features: 414 (23 audio + 5 text + 2 sentiment + 384 embeddings)\")\n",
    "print(f\"Artist Features: log_total_artist_followers + avg_artist_popularity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bee8152",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ† Best Models Summary (Quick Overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd11f6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best model for each target\n",
    "best_models = df.loc[df.groupby('target')['r2'].idxmax()][['target', 'model', 'r2', 'rmse', 'mae']]\n",
    "best_models = best_models.sort_values('r2', ascending=False)\n",
    "\n",
    "styled_best = best_models.style.format({\n",
    "    'r2': '{:.4f}',\n",
    "    'rmse': '{:.4f}',\n",
    "    'mae': '{:.4f}'\n",
    "}).set_caption('Best Model Per Target').set_table_styles([\n",
    "    {'selector': 'caption', 'props': [('font-size', '18px'), ('font-weight', 'bold'), ('color', '#2E86AB')]}\n",
    "])\n",
    "\n",
    "display(styled_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30315d7",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸŽ­ Valence Models (Emotional Positivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4752b1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_styled_table(df, target, sort_by='r2', ascending=False):\n",
    "    \"\"\"Create a beautifully styled table for a specific target, separated by default and tuned\"\"\"\n",
    "    target_df = df[df['target'] == target].copy()\n",
    "    target_df = target_df.sort_values(sort_by, ascending=ascending)\n",
    "    \n",
    "    # Select key columns\n",
    "    cols = ['model', 'r2', 'rmse', 'mae', 'explained_variance', 'train_time_seconds']\n",
    "    target_df = target_df[cols].reset_index(drop=True)\n",
    "    \n",
    "    # Split into default and tuned\n",
    "    default_df = target_df[~target_df['model'].str.contains('_tuned')].copy()\n",
    "    tuned_df = target_df[target_df['model'].str.contains('_tuned')].copy()\n",
    "    \n",
    "    # Add ranks\n",
    "    default_df['rank'] = range(1, len(default_df) + 1)\n",
    "    tuned_df['rank'] = range(1, len(tuned_df) + 1)\n",
    "    \n",
    "    default_df = default_df[['rank'] + cols]\n",
    "    tuned_df = tuned_df[['rank'] + cols]\n",
    "    \n",
    "    # Display both tables\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{target.upper()} - DEFAULT MODELS\")\n",
    "    print('='*80)\n",
    "    \n",
    "    styled_default = default_df.style.format({\n",
    "        'r2': '{:.4f}',\n",
    "        'rmse': '{:.4f}',\n",
    "        'mae': '{:.4f}',\n",
    "        'explained_variance': '{:.4f}',\n",
    "        'train_time_seconds': '{:.1f}s'\n",
    "    }).set_caption(\n",
    "        f'{target.upper()} - Default Models (Sorted by RÂ²)'\n",
    "    ).set_table_styles([\n",
    "        {'selector': 'caption', 'props': [('font-size', '14px'), ('font-weight', 'bold'), ('color', '#2E86AB')]},\n",
    "        {'selector': 'th', 'props': [('background-color', '#4A90D9'), ('color', 'white')]},\n",
    "    ])\n",
    "    display(styled_default)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{target.upper()} - TUNED MODELS\")\n",
    "    print('='*80)\n",
    "    \n",
    "    styled_tuned = tuned_df.style.format({\n",
    "        'r2': '{:.4f}',\n",
    "        'rmse': '{:.4f}',\n",
    "        'mae': '{:.4f}',\n",
    "        'explained_variance': '{:.4f}',\n",
    "        'train_time_seconds': '{:.1f}s'\n",
    "    }).set_caption(\n",
    "        f'{target.upper()} - Tuned Models (Sorted by RÂ²)'\n",
    "    ).set_table_styles([\n",
    "        {'selector': 'caption', 'props': [('font-size', '14px'), ('font-weight', 'bold'), ('color', '#F18F01')]},\n",
    "        {'selector': 'th', 'props': [('background-color', '#F18F01'), ('color', 'white')]},\n",
    "    ])\n",
    "    display(styled_tuned)\n",
    "\n",
    "create_styled_table(df, 'valence')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556ba91e",
   "metadata": {},
   "source": [
    "---\n",
    "## âš¡ Energy Models (Intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979e1aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(create_styled_table(df, 'energy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b13c9b9",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ’ƒ Danceability Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3c7e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(create_styled_table(df, 'danceability'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50becc1c",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸŒŸ Popularity Models (Hardest Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273f1005",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(create_styled_table(df, 'popularity'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dccba25",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ“ˆ Visual Comparison: RÂ² Scores Across All Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbd7830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate RÂ² comparison heatmaps for default and tuned models - Enhanced styling\n",
    "df_default = df[~df['model'].str.contains('_tuned')].copy()\n",
    "df_tuned = df[df['model'].str.contains('_tuned')].copy()\n",
    "\n",
    "# Clean model names for tuned (remove _tuned suffix)\n",
    "df_tuned['model_clean'] = df_tuned['model'].str.replace('_tuned', '')\n",
    "\n",
    "# Create pivots\n",
    "pivot_default = df_default.pivot(index='model', columns='target', values='r2')\n",
    "pivot_tuned = df_tuned.pivot(index='model_clean', columns='target', values='r2')\n",
    "\n",
    "# Order columns\n",
    "target_order = ['valence', 'energy', 'danceability', 'popularity']\n",
    "pivot_default = pivot_default[target_order]\n",
    "pivot_tuned = pivot_tuned[target_order]\n",
    "\n",
    "# Sort by average RÂ²\n",
    "pivot_default['avg_r2'] = pivot_default.mean(axis=1)\n",
    "pivot_default = pivot_default.sort_values('avg_r2', ascending=False).drop('avg_r2', axis=1)\n",
    "\n",
    "pivot_tuned['avg_r2'] = pivot_tuned.mean(axis=1)\n",
    "pivot_tuned = pivot_tuned.sort_values('avg_r2', ascending=False).drop('avg_r2', axis=1)\n",
    "\n",
    "# Create side-by-side heatmaps with enhanced styling\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "# Default models\n",
    "\n",
    "sns.heatmap(pivot_default, annot=True, fmt='.3f', cmap='RdYlGn', center=0.3,\n",
    "            linewidths=2, linecolor='white', ax=axes[0], vmin=-0.2, vmax=0.9,\n",
    "            cbar_kws={'shrink': 0.85},\n",
    "            annot_kws={'fontsize': 12, 'weight': 'bold'})\n",
    "axes[0].set_title('Default Models - RÂ² Scores', fontsize=17, fontweight='bold', pad=20)\n",
    "axes[0].set_xlabel('Target', fontsize=15, fontweight='bold', labelpad=10)\n",
    "axes[0].set_ylabel('Model', fontsize=15, fontweight='bold', labelpad=10)\n",
    "axes[0].tick_params(axis='x', labelsize=14, width=1.5)\n",
    "axes[0].tick_params(axis='y', labelsize=13, width=1.5)\n",
    "plt.setp(axes[0].get_xticklabels(), fontweight='bold')\n",
    "plt.setp(axes[0].get_yticklabels(), fontweight='bold')\n",
    "\n",
    "# Tuned models\n",
    "sns.heatmap(pivot_tuned, annot=True, fmt='.3f', cmap='RdYlGn', center=0.3,\n",
    "            linewidths=2, linecolor='white', ax=axes[1], vmin=-0.2, vmax=0.9,\n",
    "            cbar_kws={'shrink': 0.85},\n",
    "            annot_kws={'fontsize': 12, 'weight': 'bold'})\n",
    "axes[1].set_title('Tuned Models - RÂ² Scores', fontsize=17, fontweight='bold', pad=20)\n",
    "axes[1].set_xlabel('Target', fontsize=15, fontweight='bold', labelpad=10)\n",
    "axes[1].set_ylabel('Model', fontsize=15, fontweight='bold', labelpad=10)\n",
    "axes[1].tick_params(axis='x', labelsize=14, width=1.5)\n",
    "axes[1].tick_params(axis='y', labelsize=13, width=1.5)\n",
    "plt.setp(axes[1].get_xticklabels(), fontweight='bold')\n",
    "plt.setp(axes[1].get_yticklabels(), fontweight='bold')\n",
    "\n",
    "# plt.suptitle('RÂ² Scores Comparison', \n",
    "#              fontsize=19, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/experiment2_r2_heatmap_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: results/figures/experiment2_r2_heatmap_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c788cd",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ“Š Top 5 Models Bar Chart Per Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6c5fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate bar charts for default and tuned models - Enhanced styling\n",
    "targets = ['valence', 'energy', 'danceability', 'popularity']\n",
    "\n",
    "# Default models\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "for ax, target in zip(axes.flatten(), targets):\n",
    "    top_models = df_default[df_default['target'] == target].nlargest(6, 'r2')\n",
    "    \n",
    "    bars = ax.barh(top_models['model'], top_models['r2'], color='#4A90D9', \n",
    "                   edgecolor='black', alpha=0.85, linewidth=1.5)\n",
    "    ax.set_xlabel('RÂ² Score', fontsize=14, fontweight='bold', labelpad=8)\n",
    "    ax.set_title(f'{target.upper()}', fontsize=15, fontweight='bold', pad=15)\n",
    "    ax.set_xlim(0, max(top_models['r2']) * 1.15)\n",
    "    ax.grid(True, alpha=0.3, axis='x', linestyle='--', linewidth=1.2)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(1.5)\n",
    "    ax.spines['bottom'].set_linewidth(1.5)\n",
    "    ax.tick_params(axis='both', width=1.2, labelsize=12)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, val in zip(bars, top_models['r2']):\n",
    "        ax.text(val + 0.01, bar.get_y() + bar.get_height()/2, f'{val:.3f}', \n",
    "                va='center', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    ax.invert_yaxis()\n",
    "    plt.setp(ax.get_yticklabels(), fontweight='bold', fontsize=12)\n",
    "\n",
    "plt.suptitle('Default Models', \n",
    "             fontsize=17, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/experiment2_default_models.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: results/figures/experiment2_default_models.png\")\n",
    "\n",
    "# Tuned models\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "for ax, target in zip(axes.flatten(), targets):\n",
    "    top_models = df_tuned[df_tuned['target'] == target].nlargest(6, 'r2')\n",
    "    \n",
    "    bars = ax.barh(top_models['model'], top_models['r2'], color='#F18F01', \n",
    "                   edgecolor='black', alpha=0.85, linewidth=1.5)\n",
    "    ax.set_xlabel('RÂ² Score', fontsize=14, fontweight='bold', labelpad=8)\n",
    "    ax.set_title(f'{target.upper()}', fontsize=15, fontweight='bold', pad=15)\n",
    "    ax.set_xlim(0, max(top_models['r2']) * 1.15)\n",
    "    ax.grid(True, alpha=0.3, axis='x', linestyle='--', linewidth=1.2)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(1.5)\n",
    "    ax.spines['bottom'].set_linewidth(1.5)\n",
    "    ax.tick_params(axis='both', width=1.2, labelsize=12)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, val in zip(bars, top_models['r2']):\n",
    "        ax.text(val + 0.01, bar.get_y() + bar.get_height()/2, f'{val:.3f}', \n",
    "                va='center', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    ax.invert_yaxis()\n",
    "    plt.setp(ax.get_yticklabels(), fontweight='bold', fontsize=12)\n",
    "\n",
    "plt.suptitle('Tuned Models', \n",
    "             fontsize=17, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/experiment2_tuned_models.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: results/figures/experiment2_tuned_models.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f363538d",
   "metadata": {},
   "source": [
    "---\n",
    "## â±ï¸ Training Time Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34288640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate training time by model - Enhanced styling\n",
    "time_by_model = df.groupby('model')['train_time_seconds'].mean().sort_values(ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(time_by_model)))\n",
    "bars = ax.barh(time_by_model.index, time_by_model.values, color=colors, \n",
    "               edgecolor='black', alpha=0.85, linewidth=1.5)\n",
    "ax.set_xlabel('Average Training Time (seconds)', fontsize=15, fontweight='bold', labelpad=10)\n",
    "ax.set_title('Average Training Time by Model', fontsize=17, fontweight='bold', pad=20)\n",
    "ax.invert_yaxis()\n",
    "ax.grid(True, alpha=0.3, axis='x', linestyle='--', linewidth=1.2)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_linewidth(1.5)\n",
    "ax.spines['bottom'].set_linewidth(1.5)\n",
    "ax.tick_params(axis='both', width=1.2, labelsize=12)\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, time_by_model.values):\n",
    "    if val > 100:\n",
    "        label = f'{val/60:.1f}m'\n",
    "    else:\n",
    "        label = f'{val:.1f}s'\n",
    "    ax.text(val + 10, bar.get_y() + bar.get_height()/2, label, \n",
    "            va='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.setp(ax.get_yticklabels(), fontweight='bold', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/experiment2_training_time_selected.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: results/figures/experiment2_training_time_selected.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b272d19",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ“‰ RMSE Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1151ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate RMSE comparison for default and tuned models - Enhanced styling\n",
    "targets = ['valence', 'energy', 'danceability', 'popularity']\n",
    "\n",
    "# Default models RMSE\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "for ax, target in zip(axes.flatten(), targets):\n",
    "    top_models = df_default[df_default['target'] == target].nsmallest(6, 'rmse')\n",
    "    \n",
    "    bars = ax.barh(top_models['model'], top_models['rmse'], color='#60276d', \n",
    "                   edgecolor='black', alpha=0.85, linewidth=1.5)\n",
    "    ax.set_xlabel('RMSE', fontsize=14, fontweight='bold', labelpad=8)\n",
    "    ax.set_title(f'{target.upper()}', fontsize=15, fontweight='bold', pad=15)\n",
    "    ax.grid(True, alpha=0.3, axis='x', linestyle='--', linewidth=1.2)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(1.5)\n",
    "    ax.spines['bottom'].set_linewidth(1.5)\n",
    "    ax.tick_params(axis='both', width=1.2, labelsize=12)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, val in zip(bars, top_models['rmse']):\n",
    "        ax.text(val + 0.001, bar.get_y() + bar.get_height()/2, f'{val:.4f}', \n",
    "                va='center', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    ax.invert_yaxis()\n",
    "    plt.setp(ax.get_yticklabels(), fontweight='bold', fontsize=12)\n",
    "\n",
    "plt.suptitle('Default Models', \n",
    "             fontsize=17, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/experiment2_default_rmse.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: results/figures/experiment2_default_rmse.png\")\n",
    "\n",
    "# Tuned models RMSE\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "for ax, target in zip(axes.flatten(), targets):\n",
    "    top_models = df_tuned[df_tuned['target'] == target].nsmallest(6, 'rmse')\n",
    "    \n",
    "    bars = ax.barh(top_models['model'], top_models['rmse'], color='#F18F01', \n",
    "                   edgecolor='black', alpha=0.85, linewidth=1.5)\n",
    "    ax.set_xlabel('RMSE', fontsize=14, fontweight='bold', labelpad=8)\n",
    "    ax.set_title(f'{target.upper()}', fontsize=15, fontweight='bold', pad=15)\n",
    "    ax.grid(True, alpha=0.3, axis='x', linestyle='--', linewidth=1.2)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(1.5)\n",
    "    ax.spines['bottom'].set_linewidth(1.5)\n",
    "    ax.tick_params(axis='both', width=1.2, labelsize=12)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, val in zip(bars, top_models['rmse']):\n",
    "        ax.text(val + 0.001, bar.get_y() + bar.get_height()/2, f'{val:.4f}', \n",
    "                va='center', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    ax.invert_yaxis()\n",
    "    plt.setp(ax.get_yticklabels(), fontweight='bold', fontsize=12)\n",
    "\n",
    "plt.suptitle('Tuned Models', \n",
    "             fontsize=17, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/experiment2_tuned_rmse.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: results/figures/experiment2_tuned_rmse.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bde1e8",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ”¬ Default vs Tuned Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af62b994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare default vs tuned versions\n",
    "tuned_models = df[df['model'].str.contains('_tuned')].copy()\n",
    "tuned_models['base_model'] = tuned_models['model'].str.replace('_tuned', '')\n",
    "\n",
    "default_models = df[~df['model'].str.contains('_tuned')].copy()\n",
    "default_models['base_model'] = default_models['model']\n",
    "\n",
    "# Merge to compare\n",
    "comparison = tuned_models.merge(\n",
    "    default_models[['target', 'base_model', 'r2', 'rmse']], \n",
    "    on=['target', 'base_model'], \n",
    "    suffixes=('_tuned', '_default')\n",
    ")\n",
    "comparison['r2_improvement'] = comparison['r2_tuned'] - comparison['r2_default']\n",
    "comparison['rmse_improvement'] = comparison['rmse_default'] - comparison['rmse_tuned']  # Positive = better\n",
    "\n",
    "# Display improvement summary\n",
    "improvement_summary = comparison.groupby('base_model').agg({\n",
    "    'r2_improvement': 'mean',\n",
    "    'rmse_improvement': 'mean'\n",
    "}).sort_values('r2_improvement', ascending=False)\n",
    "\n",
    "print(\"Tuning Impact (Average across all targets):\")\n",
    "print(\"=\"*50)\n",
    "styled_improvement = improvement_summary.style.format({\n",
    "    'r2_improvement': '{:+.4f}',\n",
    "    'rmse_improvement': '{:+.4f}'\n",
    "}).set_caption(\n",
    "    'Tuning Impact: Positive = Improvement'\n",
    ").set_table_styles([\n",
    "    {'selector': 'caption', 'props': [('font-size', '16px'), ('font-weight', 'bold')]},\n",
    "])\n",
    "display(styled_improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a333cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize tuning impact - Enhanced styling\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "x = np.arange(len(improvement_summary))\n",
    "width = 0.6\n",
    "\n",
    "bars = ax.bar(x, improvement_summary['r2_improvement'], width, \n",
    "              color=['#90EE90' if v > 0 else '#FF6B6B' for v in improvement_summary['r2_improvement']],\n",
    "              edgecolor='black', alpha=0.85, linewidth=1.5)\n",
    "\n",
    "ax.set_xlabel('Model', fontsize=15, fontweight='bold', labelpad=10)\n",
    "ax.set_ylabel('RÂ² Improvement (Tuned - Default)', fontsize=15, fontweight='bold', labelpad=10)\n",
    "ax.set_title('Hyperparameter Tuning Impact on RÂ²', \n",
    "             fontsize=17, fontweight='bold', pad=20)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(improvement_summary.index, rotation=45, ha='right', fontweight='bold', fontsize=12)\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=2)\n",
    "ax.grid(True, alpha=0.3, axis='y', linestyle='--', linewidth=1.2)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_linewidth(1.5)\n",
    "ax.spines['bottom'].set_linewidth(1.5)\n",
    "ax.tick_params(axis='both', width=1.2, labelsize=12)\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, improvement_summary['r2_improvement']):\n",
    "    y_pos = val + 0.003 if val >= 0 else val - 0.012\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, y_pos, f'{val:+.3f}', \n",
    "            ha='center', va='bottom' if val >= 0 else 'top', \n",
    "            fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/experiment2_tuning_impact_selected.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: results/figures/experiment2_tuning_impact_selected.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1575835",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ“‹ Complete Results Table (All Models, All Targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e922498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive tables separated by default and tuned\n",
    "full_table = df[['target', 'model', 'r2', 'rmse', 'mae', 'explained_variance', \n",
    "                 'pred_mean', 'pred_std', 'residual_mean', 'residual_std', 'train_time_seconds']].copy()\n",
    "\n",
    "# Default models\n",
    "default_table = full_table[~full_table['model'].str.contains('_tuned')].copy()\n",
    "default_table = default_table.sort_values(['target', 'r2'], ascending=[True, False])\n",
    "\n",
    "# Tuned models\n",
    "tuned_table = full_table[full_table['model'].str.contains('_tuned')].copy()\n",
    "tuned_table = tuned_table.sort_values(['target', 'r2'], ascending=[True, False])\n",
    "\n",
    "def color_by_target(val):\n",
    "    colors = {\n",
    "        'valence': 'background-color: #E8F4FD',\n",
    "        'energy': 'background-color: #FDF4E8',\n",
    "        'danceability': 'background-color: #F4E8FD',\n",
    "        'popularity': 'background-color: #E8FDF4'\n",
    "    }\n",
    "    return colors.get(val, '')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DEFAULT MODELS - COMPLETE RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "styled_default = default_table.style.format({\n",
    "    'r2': '{:.4f}',\n",
    "    'rmse': '{:.4f}',\n",
    "    'mae': '{:.4f}',\n",
    "    'explained_variance': '{:.4f}',\n",
    "    'pred_mean': '{:.4f}',\n",
    "    'pred_std': '{:.4f}',\n",
    "    'residual_mean': '{:.4f}',\n",
    "    'residual_std': '{:.4f}',\n",
    "    'train_time_seconds': '{:.1f}'\n",
    "}).applymap(color_by_target, subset=['target']).set_caption(\n",
    "    'Default Models - Complete Results'\n",
    ").set_table_styles([\n",
    "    {'selector': 'caption', 'props': [('font-size', '16px'), ('font-weight', 'bold')]},\n",
    "    {'selector': 'th', 'props': [('background-color', '#4A90D9'), ('color', 'white')]},\n",
    "])\n",
    "\n",
    "display(styled_default)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TUNED MODELS - COMPLETE RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "styled_tuned = tuned_table.style.format({\n",
    "    'r2': '{:.4f}',\n",
    "    'rmse': '{:.4f}',\n",
    "    'mae': '{:.4f}',\n",
    "    'explained_variance': '{:.4f}',\n",
    "    'pred_mean': '{:.4f}',\n",
    "    'pred_std': '{:.4f}',\n",
    "    'residual_mean': '{:.4f}',\n",
    "    'residual_std': '{:.4f}',\n",
    "    'train_time_seconds': '{:.1f}'\n",
    "}).applymap(color_by_target, subset=['target']).set_caption(\n",
    "    'Tuned Models - Complete Results'\n",
    ").set_table_styles([\n",
    "    {'selector': 'caption', 'props': [('font-size', '16px'), ('font-weight', 'bold')]},\n",
    "    {'selector': 'th', 'props': [('background-color', '#F18F01'), ('color', 'white')]},\n",
    "])\n",
    "\n",
    "display(styled_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92eae2e",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸŽ¯ Final Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07052be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 2 models per target for both default and tuned\n",
    "recommendations = []\n",
    "targets = ['valence', 'energy', 'danceability', 'popularity']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FINAL RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for target in targets:\n",
    "    print(f\"\\n{target.upper()}:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Top default model\n",
    "    top_default = df_default[df_default['target'] == target].nlargest(1, 'r2').iloc[0]\n",
    "    print(f\"  Default: {top_default['model']}\")\n",
    "    print(f\"    RÂ² = {top_default['r2']:.4f} | RMSE = {top_default['rmse']:.4f} | Time = {top_default['train_time_seconds']:.1f}s\")\n",
    "    \n",
    "    # Top tuned model\n",
    "    top_tuned = df_tuned[df_tuned['target'] == target].nlargest(1, 'r2').iloc[0]\n",
    "    print(f\"  Tuned:   {top_tuned['model']}\")\n",
    "    print(f\"    RÂ² = {top_tuned['r2']:.4f} | RMSE = {top_tuned['rmse']:.4f} | Time = {top_tuned['train_time_seconds']:.1f}s\")\n",
    "    \n",
    "    # Improvement\n",
    "    r2_imp = top_tuned['r2'] - top_default['r2']\n",
    "    rmse_imp = top_default['rmse'] - top_tuned['rmse']\n",
    "    print(f\"  Improvement: RÂ² {r2_imp:+.4f} | RMSE {rmse_imp:+.4f}\")\n",
    "    \n",
    "    # Add to recommendations\n",
    "    rec_default = top_default[['target', 'model', 'r2', 'rmse', 'train_time_seconds']].to_dict()\n",
    "    rec_default['type'] = 'Default'\n",
    "    recommendations.append(rec_default)\n",
    "    \n",
    "    rec_tuned = top_tuned[['target', 'model', 'r2', 'rmse', 'train_time_seconds']].to_dict()\n",
    "    rec_tuned['type'] = 'Tuned'\n",
    "    recommendations.append(rec_tuned)\n",
    "\n",
    "# Create recommendations dataframe\n",
    "rec_df = pd.DataFrame(recommendations)\n",
    "rec_df = rec_df[['target', 'type', 'model', 'r2', 'rmse', 'train_time_seconds']]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECOMMENDATIONS TABLE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "styled_rec = rec_df.style.format({\n",
    "    'r2': '{:.4f}',\n",
    "    'rmse': '{:.4f}',\n",
    "    'train_time_seconds': '{:.1f}s'\n",
    "}).set_caption('ðŸŽ¯ Final Model Recommendations').set_table_styles([\n",
    "    {'selector': 'caption', 'props': [('font-size', '18px'), ('font-weight', 'bold'), ('color', '#2E86AB')]},\n",
    "    {'selector': 'th', 'props': [('background-color', '#2E86AB'), ('color', 'white')]},\n",
    "])\n",
    "\n",
    "display(styled_rec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
