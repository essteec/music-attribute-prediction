{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2236196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Enhanced Academic publication style settings\n",
    "plt.style.use('seaborn-v0_8-paper')\n",
    "sns.set_context(\"paper\", font_scale=1.6)\n",
    "sns.set_palette(\"deep\")\n",
    "\n",
    "# Configure matplotlib for publication quality with BOLD and BIGGER fonts\n",
    "plt.rcParams['figure.figsize'] = (14, 7)\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman', 'DejaVu Serif']\n",
    "plt.rcParams['font.size'] = 13\n",
    "plt.rcParams['axes.labelsize'] = 15\n",
    "plt.rcParams['axes.titlesize'] = 17\n",
    "plt.rcParams['axes.titleweight'] = 'bold'\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['xtick.labelsize'] = 13\n",
    "plt.rcParams['ytick.labelsize'] = 13\n",
    "plt.rcParams['legend.fontsize'] = 12\n",
    "plt.rcParams['legend.frameon'] = True\n",
    "plt.rcParams['legend.edgecolor'] = 'black'\n",
    "plt.rcParams['legend.title_fontsize'] = 13\n",
    "plt.rcParams['axes.linewidth'] = 1.5\n",
    "plt.rcParams['grid.alpha'] = 0.3\n",
    "plt.rcParams['grid.linestyle'] = '--'\n",
    "plt.rcParams['xtick.major.width'] = 1.2\n",
    "plt.rcParams['ytick.major.width'] = 1.2\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")\n",
    "print(\"Enhanced academic publication style configured\")\n",
    "print(\"Experiment 2: WITH Artist Features (414 features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815370e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths for Experiment 2\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "FEATURES_DIR = PROJECT_ROOT / \"features\"\n",
    "MODELS_DIR = PROJECT_ROOT / \"models\" / \"saved\" / \"experiment2_with_artist\"\n",
    "RESULTS_DIR = PROJECT_ROOT / \"results\" / \"metrics\" / \"experiment2_with_artist\"\n",
    "FIGURES_DIR = PROJECT_ROOT / \"results\" / \"figures\"\n",
    "\n",
    "# Configuration\n",
    "TARGETS = ['valence', 'energy', 'danceability', 'popularity']\n",
    "SELECTED_MODELS = [\n",
    "    'CatBoost', 'CatBoost_tuned',\n",
    "    'LightGBM', 'LightGBM_tuned',\n",
    "    'XGBoost', 'XGBoost_tuned',\n",
    "    'ExtraTrees', 'ExtraTrees_tuned',\n",
    "    'MLPRegressor', 'MLPRegressor_tuned',\n",
    "    'RandomForest', 'RandomForest_tuned'\n",
    "]\n",
    "\n",
    "print(f\"Models directory: {MODELS_DIR}\")\n",
    "print(f\"Results directory: {RESULTS_DIR}\")\n",
    "print(f\"Features directory: {FEATURES_DIR}\")\n",
    "print(f\"Targets: {TARGETS}\")\n",
    "print(f\"Selected models: {len(SELECTED_MODELS)} models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60645de0",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ“‹ Load Feature Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874ec4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_feature_names():\n",
    "    \"\"\"Load feature names from metadata with proper audio feature names\"\"\"\n",
    "    metadata_path = FEATURES_DIR / \"preprocessing_metadata.json\"\n",
    "    \n",
    "    feature_names = []\n",
    "    \n",
    "    # Audio features (23 for Experiment 2 - includes 2 artist features)\n",
    "    audio_names_path = FEATURES_DIR / \"audio_feature_names.txt\"\n",
    "    if audio_names_path.exists():\n",
    "        with open(audio_names_path, 'r') as f:\n",
    "            audio_features = [line.strip() for line in f \n",
    "                            if line.strip() and not line.strip().startswith('#')]\n",
    "        feature_names.extend(audio_features)\n",
    "        print(f\"Loaded {len(audio_features)} audio features from file\")\n",
    "    else:\n",
    "        # Fallback: use standard Spotify audio feature names\n",
    "        audio_features = [\n",
    "            'danceability', 'energy', 'loudness', 'speechiness', \n",
    "            'acousticness', 'instrumentalness', 'liveness', 'tempo',\n",
    "            'genre_Rock', 'genre_Pop', 'genre_Hip-Hop', 'genre_Electronic',\n",
    "            'genre_Jazz', 'genre_Classical', 'genre_Country', 'genre_R&B',\n",
    "            'genre_Indie', 'genre_Metal', 'year_normalized', 'mode',\n",
    "            'key_sin', 'log_total_artist_followers', 'avg_artist_popularity'\n",
    "        ]\n",
    "        feature_names.extend(audio_features)\n",
    "        print(f\"Audio feature file not found, using default names\")\n",
    "    \n",
    "    # Text stats (5)\n",
    "    text_stats = ['word_count', 'unique_word_count', 'unique_ratio', 'avg_word_length', 'char_count']\n",
    "    feature_names.extend(text_stats)\n",
    "    \n",
    "    # Sentiment (2)\n",
    "    sentiment = ['sentiment_polarity', 'sentiment_subjectivity']\n",
    "    feature_names.extend(sentiment)\n",
    "    \n",
    "    # Embeddings (384)\n",
    "    embedding_names = [f'emb_{i}' for i in range(384)]\n",
    "    feature_names.extend(embedding_names)\n",
    "    \n",
    "    return feature_names\n",
    "\n",
    "feature_names = load_feature_names()\n",
    "print(f\"Total features loaded: {len(feature_names)}\")\n",
    "print(f\"\\nFirst 32 features (including artist features):\")\n",
    "for i, name in enumerate(feature_names[:32]):\n",
    "    print(f\" {i:3d}. {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594993d7",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ”§ Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4421b444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance(model, model_name, feature_names):\n",
    "    \"\"\"Extract feature importance from a model\"\"\"\n",
    "    \n",
    "    importance = None\n",
    "    method = None\n",
    "    \n",
    "    # Tree-based models with feature_importances_\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importance = model.feature_importances_\n",
    "        method = 'feature_importances_'\n",
    "    \n",
    "    # MLPRegressor - use first layer weights\n",
    "    elif hasattr(model, 'coefs_') and len(model.coefs_) > 0:\n",
    "        # Sum absolute weights from input to first hidden layer\n",
    "        first_layer_weights = model.coefs_[0]\n",
    "        importance = np.abs(first_layer_weights).sum(axis=1)\n",
    "        method = 'mlp_first_layer'\n",
    "    \n",
    "    # Linear models with coef_\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        importance = np.abs(model.coef_)\n",
    "        if importance.ndim > 1:\n",
    "            importance = importance.mean(axis=0)\n",
    "        method = 'coef_'\n",
    "    \n",
    "    if importance is not None:\n",
    "        # Verify shape\n",
    "        if len(importance) != len(feature_names):\n",
    "            print(f\"Shape mismatch: {len(importance)} vs {len(feature_names)}\")\n",
    "            return None\n",
    "        \n",
    "        # Normalize\n",
    "        if importance.sum() > 0:\n",
    "            importance = importance / importance.sum()\n",
    "        \n",
    "        return pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': importance,\n",
    "            'method': method\n",
    "        }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def analyze_model_importance(target, model_name, feature_names):\n",
    "    \"\"\"Analyze feature importance for a specific model and target\"\"\"\n",
    "    \n",
    "    model_path = MODELS_DIR / f\"{model_name}_{target}.pkl\"\n",
    "    \n",
    "    if not model_path.exists():\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        model = joblib.load(model_path)\n",
    "        importance_df = get_feature_importance(model, model_name, feature_names)\n",
    "        \n",
    "        if importance_df is not None:\n",
    "            importance_df['target'] = target\n",
    "            importance_df['model'] = model_name\n",
    "            return importance_df\n",
    "        return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {model_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276ec587",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸš€ Extract Feature Importance from All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d5be8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Extracting feature importance...\\n\")\n",
    "\n",
    "all_importance = []\n",
    "\n",
    "for target in TARGETS:\n",
    "    print(f\"\\n{target.upper()}\")\n",
    "    \n",
    "    for model_name in SELECTED_MODELS:\n",
    "        result = analyze_model_importance(target, model_name, feature_names)\n",
    "        if result is not None:\n",
    "            all_importance.append(result)\n",
    "            top_feat = result.iloc[0]['feature']\n",
    "            top_imp = result.iloc[0]['importance']\n",
    "            print(f\"   {model_name:20s} â†’ {top_feat} ({top_imp:.3f})\")\n",
    "        else:\n",
    "            print(f\"   {model_name:20s} â†’ Failed\")\n",
    "        \n",
    "\n",
    "# Combine all results\n",
    "all_importance_df = pd.concat(all_importance, ignore_index=True)\n",
    "\n",
    "print(f\"\\nExtracted importance for {len(all_importance)} model-target combinations\")\n",
    "print(f\"Total data points: {len(all_importance_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530daa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save raw data\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "raw_path = RESULTS_DIR / f\"feature_importance_raw_{timestamp}.csv\"\n",
    "\n",
    "print(f\"Saving to: {raw_path}\")\n",
    "print(f\"DataFrame shape: {all_importance_df.shape}\")\n",
    "print(f\"Directory exists: {RESULTS_DIR.exists()}\")\n",
    "\n",
    "all_importance_df.to_csv(raw_path, index=False)\n",
    "\n",
    "# Verify file was saved\n",
    "if raw_path.exists():\n",
    "    file_size = raw_path.stat().st_size / 1024\n",
    "    print(f\"Saved raw importance data: {raw_path.name} ({file_size:.1f} KB)\")\n",
    "else:\n",
    "    print(f\"ERROR: File was not saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f8a13e",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ“Š Top 20 Features per Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bed7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TOP 20 FEATURES PER TARGET (averaged across models)\\n\")\n",
    "\n",
    "summary_data = []\n",
    "\n",
    "for target in TARGETS:\n",
    "    target_df = all_importance_df[all_importance_df['target'] == target]\n",
    "    top20 = target_df.groupby('feature')['importance'].mean().nlargest(20)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"{target.upper()}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    for i, (feat, imp) in enumerate(top20.items(), 1):\n",
    "        print(f\"   {i:2d}. {feat:<30s} {imp:.4f}\")\n",
    "        summary_data.append({\n",
    "            'target': target,\n",
    "            'rank': i,\n",
    "            'feature': feat,\n",
    "            'avg_importance': imp\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_path = RESULTS_DIR / f\"feature_importance_summary_{timestamp}.csv\"\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "print(f\"\\nSaved summary: {summary_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c905517c",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ“ˆ Visualization 1: Top 20 Features per Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae9530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_features(all_importance, target, top_n=20):\n",
    "    \"\"\"Plot top N features for a target with enhanced academic styling\"\"\"\n",
    "    target_df = all_importance[all_importance['target'] == target].copy()\n",
    "    agg_importance = target_df.groupby('feature')['importance'].mean().sort_values(ascending=False)\n",
    "    top_features = agg_importance.head(top_n)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 9))\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(top_features)))\n",
    "    \n",
    "    bars = ax.barh(range(len(top_features)), top_features.values, \n",
    "                   color=colors, edgecolor='black', alpha=0.85, linewidth=1.5)\n",
    "    ax.set_yticks(range(len(top_features)))\n",
    "    ax.set_yticklabels(top_features.index, fontweight='bold', fontsize=12)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel('Average Importance', fontsize=15, fontweight='bold', labelpad=10)\n",
    "    ax.set_title(f'Experiment 2: Top {top_n} Features for {target.upper()}', \n",
    "                 fontsize=17, fontweight='bold', pad=20)\n",
    "    ax.grid(True, alpha=0.3, axis='x', linestyle='--', linewidth=1.2)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(1.5)\n",
    "    ax.spines['bottom'].set_linewidth(1.5)\n",
    "    ax.tick_params(axis='both', width=1.2)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, val in zip(bars, top_features.values):\n",
    "        ax.text(val + 0.001, bar.get_y() + bar.get_height()/2, \n",
    "                f'{val:.3f}', va='center', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Generate plots for all targets\n",
    "for target in TARGETS:\n",
    "    fig = plot_top_features(all_importance_df, target, top_n=20)\n",
    "    fig_path = FIGURES_DIR / f\"experiment2_feature_importance_{target}.png\"\n",
    "    fig.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Saved: {fig_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d28433",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ“Š Visualization 2: Feature Group Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68ee1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_groups():\n",
    "    \"\"\"Define feature groups including artist features\"\"\"\n",
    "    groups = {\n",
    "        'audio_continuous': list(range(0, 7)),\n",
    "        'year': [7],\n",
    "        'mode': [8],\n",
    "        'key_cyclical': [9, 10],\n",
    "        'genre': list(range(11, 21)),\n",
    "        'artist': [21, 22],  # NEW: log_total_artist_followers + avg_artist_popularity\n",
    "        'text_stats': list(range(23, 28)),\n",
    "        'sentiment': list(range(28, 30)),\n",
    "        'embeddings': list(range(30, 414)),\n",
    "    }\n",
    "    return groups\n",
    "\n",
    "def aggregate_by_group(importance_df, feature_names):\n",
    "    \"\"\"Aggregate feature importance by group\"\"\"\n",
    "    groups = create_feature_groups()\n",
    "    group_importance = {}\n",
    "    \n",
    "    for group_name, indices in groups.items():\n",
    "        group_features = [feature_names[i] for i in indices if i < len(feature_names)]\n",
    "        mask = importance_df['feature'].isin(group_features)\n",
    "        group_importance[group_name] = importance_df.loc[mask, 'importance'].sum()\n",
    "    \n",
    "    return pd.Series(group_importance).sort_values(ascending=False)\n",
    "\n",
    "# Plot with enhanced styling\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#28A745', '#6C757D', '#17A2B8', '#FFC107', '#FF69B4']\n",
    "\n",
    "for ax, target in zip(axes.flatten(), TARGETS):\n",
    "    target_df = all_importance_df[all_importance_df['target'] == target]\n",
    "    \n",
    "    # Aggregate by group\n",
    "    group_data = []\n",
    "    for model in target_df['model'].unique():\n",
    "        model_df = target_df[target_df['model'] == model]\n",
    "        group_imp = aggregate_by_group(model_df, feature_names)\n",
    "        group_data.append(group_imp)\n",
    "    \n",
    "    # Average across models\n",
    "    group_df = pd.DataFrame(group_data)\n",
    "    avg_group = group_df.mean().sort_values(ascending=True)\n",
    "    \n",
    "    bars = ax.barh(range(len(avg_group)), avg_group.values, \n",
    "                  color=colors[:len(avg_group)], edgecolor='black', alpha=0.85, linewidth=1.5)\n",
    "    ax.set_yticks(range(len(avg_group)))\n",
    "    ax.set_yticklabels(avg_group.index, fontweight='bold', fontsize=12)\n",
    "    ax.set_xlabel('Importance', fontsize=14, fontweight='bold', labelpad=8)\n",
    "    ax.set_title(f'{target.upper()}', fontsize=15, fontweight='bold', pad=15)\n",
    "    ax.grid(True, alpha=0.3, axis='x', linestyle='--', linewidth=1.2)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(1.5)\n",
    "    ax.spines['bottom'].set_linewidth(1.5)\n",
    "    ax.tick_params(axis='both', width=1.2)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, val in zip(bars, avg_group.values):\n",
    "        ax.text(val + 0.005, bar.get_y() + bar.get_height()/2, \n",
    "                f'{val:.2%}', va='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Feature Group Importance by Target', \n",
    "             fontsize=17, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "fig_path = FIGURES_DIR / \"experiment2_feature_groups.png\"\n",
    "plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"Saved: {fig_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825ab542",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ”¥ Visualization 3: Model Comparison Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e323a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_comparison(all_importance, target):\n",
    "    \"\"\"Compare feature importance across models with enhanced styling\"\"\"\n",
    "    target_df = all_importance[all_importance['target'] == target].copy()\n",
    "    \n",
    "    # Separate tuned and default models (excluding MLPRegressor)\n",
    "    default_models = [m for m in SELECTED_MODELS if not m.endswith('_tuned') and 'MLPRegressor' not in m]\n",
    "    tuned_models = [m for m in SELECTED_MODELS if m.endswith('_tuned') and 'MLPRegressor' not in m]\n",
    "    \n",
    "    # Get top 15 features overall\n",
    "    top_features = target_df.groupby('feature')['importance'].mean().nlargest(15).index.tolist()\n",
    "    \n",
    "    # Create figure with 1 row, 2 columns - Enhanced sizing\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(22, 10))\n",
    "    \n",
    "    # Plot default models\n",
    "    default_df = target_df[target_df['model'].isin(default_models)]\n",
    "    pivot_default = default_df[default_df['feature'].isin(top_features)].pivot(\n",
    "        index='feature', columns='model', values='importance'\n",
    "    )\n",
    "    pivot_default = pivot_default.loc[top_features]\n",
    "    \n",
    "    sns.heatmap(pivot_default, annot=True, fmt='.3f', cmap='YlOrRd', ax=ax1,\n",
    "                linewidths=2, linecolor='white',\n",
    "                cbar_kws={'label': 'Importance', 'shrink': 0.85},\n",
    "                annot_kws={'fontsize': 10, 'weight': 'bold'})\n",
    "    ax1.set_title(f'{target.upper()} - Default Models', fontsize=16, fontweight='bold', pad=20)\n",
    "    ax1.set_xlabel('Model', fontsize=14, fontweight='bold', labelpad=10)\n",
    "    ax1.set_ylabel('Feature', fontsize=14, fontweight='bold', labelpad=10)\n",
    "    ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45, ha='right', fontweight='bold', fontsize=12)\n",
    "    ax1.set_yticklabels(ax1.get_yticklabels(), rotation=0, fontweight='bold', fontsize=12)\n",
    "    ax1.tick_params(axis='both', width=1.2)\n",
    "    \n",
    "    # Plot tuned models\n",
    "    tuned_df = target_df[target_df['model'].isin(tuned_models)]\n",
    "    pivot_tuned = tuned_df[tuned_df['feature'].isin(top_features)].pivot(\n",
    "        index='feature', columns='model', values='importance'\n",
    "    )\n",
    "    pivot_tuned = pivot_tuned.loc[top_features]\n",
    "    \n",
    "    sns.heatmap(pivot_tuned, annot=True, fmt='.3f', cmap='YlOrRd', ax=ax2,\n",
    "                linewidths=2, linecolor='white',\n",
    "                cbar_kws={'label': 'Importance', 'shrink': 0.85},\n",
    "                annot_kws={'fontsize': 10, 'weight': 'bold'})\n",
    "    ax2.set_title(f'{target.upper()} - Tuned Models', fontsize=16, fontweight='bold', pad=20)\n",
    "    ax2.set_xlabel('Model', fontsize=14, fontweight='bold', labelpad=10)\n",
    "    ax2.set_ylabel('Feature', fontsize=14, fontweight='bold', labelpad=10)\n",
    "    ax2.set_xticklabels(ax2.get_xticklabels(), rotation=45, ha='right', fontweight='bold', fontsize=12)\n",
    "    ax2.set_yticklabels(ax2.get_yticklabels(), rotation=0, fontweight='bold', fontsize=12)\n",
    "    ax2.tick_params(axis='both', width=1.2)\n",
    "    \n",
    "    plt.suptitle(f'Experiment 2: Feature Importance Comparison - {target.upper()}', \n",
    "                 fontsize=18, fontweight='bold', y=0.98)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Generate heatmaps for all targets\n",
    "for target in TARGETS:\n",
    "    fig = plot_model_comparison(all_importance_df, target)\n",
    "    fig_path = FIGURES_DIR / f\"experiment2_feature_importance_heatmap_{target}.png\"\n",
    "    fig.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Saved: {fig_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51977e79",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ”‘ Key Insights: Embedding Contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780be8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"EMBEDDING CONTRIBUTION ANALYSIS\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "embedding_cols = [f'emb_{i}' for i in range(384)]\n",
    "\n",
    "insights = []\n",
    "for target in TARGETS:\n",
    "    target_df = all_importance_df[all_importance_df['target'] == target]\n",
    "    emb_importance = target_df[target_df['feature'].isin(embedding_cols)]['importance'].sum()\n",
    "    total_importance = target_df['importance'].sum()\n",
    "    emb_pct = (emb_importance / total_importance * 100) if total_importance > 0 else 0\n",
    "    \n",
    "    print(f\"   {target.upper():15s} â†’ Embeddings: {emb_pct:5.1f}% of total importance\")\n",
    "    insights.append({'target': target, 'embedding_contribution_pct': emb_pct})\n",
    "\n",
    "insights_df = pd.DataFrame(insights)\n",
    "display(insights_df.style.format({'embedding_contribution_pct': '{:.2f}%'}).background_gradient(\n",
    "    subset=['embedding_contribution_pct'], cmap='YlOrRd'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ff58d7",
   "metadata": {},
   "source": [
    "---\n",
    "## âœ… Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e07222",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Models analyzed: {len(SELECTED_MODELS)} Ã— {len(TARGETS)} targets = {len(all_importance)} combinations\")\n",
    "print(f\"Results saved to: {RESULTS_DIR}\")\n",
    "print(f\"Figures saved to: {FIGURES_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
