{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98960245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Enhanced Academic publication style settings\n",
    "plt.style.use('seaborn-v0_8-paper')\n",
    "sns.set_context(\"paper\", font_scale=1.6)\n",
    "sns.set_palette(\"deep\")\n",
    "\n",
    "# Configure matplotlib for publication quality with BOLD and BIGGER fonts\n",
    "plt.rcParams['figure.figsize'] = (14, 7)\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman', 'DejaVu Serif']\n",
    "plt.rcParams['font.size'] = 13\n",
    "plt.rcParams['axes.labelsize'] = 15\n",
    "plt.rcParams['axes.titlesize'] = 17\n",
    "plt.rcParams['axes.titleweight'] = 'bold'\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['xtick.labelsize'] = 13\n",
    "plt.rcParams['ytick.labelsize'] = 13\n",
    "plt.rcParams['legend.fontsize'] = 12\n",
    "plt.rcParams['legend.frameon'] = True\n",
    "plt.rcParams['legend.edgecolor'] = 'black'\n",
    "plt.rcParams['legend.title_fontsize'] = 13\n",
    "plt.rcParams['axes.linewidth'] = 1.5\n",
    "plt.rcParams['grid.alpha'] = 0.3\n",
    "plt.rcParams['grid.linestyle'] = '--'\n",
    "plt.rcParams['xtick.major.width'] = 1.2\n",
    "plt.rcParams['ytick.major.width'] = 1.2\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")\n",
    "print(\"Enhanced academic publication style configured\")\n",
    "print(\"Experiment 2: WITH Artist Features (414 features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09111830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Experiment 2 results (with artist features)\n",
    "df = pd.read_csv('../results/metrics/experiment2_with_artist/enhanced_results_detailed_20251231_143812.csv')\n",
    "print(f\"Loaded {len(df)} model results from Experiment 2\")\n",
    "print(f\"Targets: {df['target'].unique().tolist()}\")\n",
    "print(f\"Models: {df['model'].nunique()} unique models\")\n",
    "print(f\"Features: 414 (23 audio + 5 text + 2 sentiment + 384 embeddings)\")\n",
    "print(f\"Artist Features: log_total_artist_followers + avg_artist_popularity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bee8152",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ† Best Models Summary (Quick Overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd11f6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best model for each target\n",
    "best_models = df.loc[df.groupby('target')['r2'].idxmax()][['target', 'model', 'r2', 'rmse', 'mae']]\n",
    "best_models = best_models.sort_values('r2', ascending=False)\n",
    "\n",
    "# Style the dataframe\n",
    "def highlight_best(s):\n",
    "    return ['background-color: #90EE90; font-weight: bold' if i == s.name else '' for i in range(len(s))]\n",
    "\n",
    "styled_best = best_models.style.format({\n",
    "    'r2': '{:.4f}',\n",
    "    'rmse': '{:.4f}',\n",
    "    'mae': '{:.4f}'\n",
    "}).set_caption('ðŸ† Best Model Per Target').set_table_styles([\n",
    "    {'selector': 'caption', 'props': [('font-size', '18px'), ('font-weight', 'bold'), ('color', '#2E86AB')]}\n",
    "])\n",
    "\n",
    "display(styled_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30315d7",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸŽ­ Valence Models (Emotional Positivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4752b1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_styled_table(df, target, sort_by='r2', ascending=False):\n",
    "    \"\"\"Create a beautifully styled table for a specific target\"\"\"\n",
    "    target_df = df[df['target'] == target].copy()\n",
    "    target_df = target_df.sort_values(sort_by, ascending=ascending)\n",
    "    \n",
    "    # Select key columns\n",
    "    cols = ['model', 'r2', 'rmse', 'mae', 'explained_variance', 'train_time_seconds']\n",
    "    target_df = target_df[cols].reset_index(drop=True)\n",
    "    target_df['rank'] = range(1, len(target_df) + 1)\n",
    "    target_df = target_df[['rank'] + cols]\n",
    "    \n",
    "    # Color coding function\n",
    "    def color_r2(val):\n",
    "        if val >= 0.6:\n",
    "            return 'background-color: #90EE90'  # Green\n",
    "        elif val >= 0.4:\n",
    "            return 'background-color: #FFFFE0'  # Light yellow\n",
    "        elif val >= 0.2:\n",
    "            return 'background-color: #FFD700'  # Gold\n",
    "        elif val >= 0:\n",
    "            return 'background-color: #FFA500'  # Orange\n",
    "        else:\n",
    "            return 'background-color: #FF6B6B'  # Red\n",
    "    \n",
    "    styled = target_df.style.format({\n",
    "        'r2': '{:.4f}',\n",
    "        'rmse': '{:.4f}',\n",
    "        'mae': '{:.4f}',\n",
    "        'explained_variance': '{:.4f}',\n",
    "        'train_time_seconds': '{:.1f}s'\n",
    "    }).applymap(color_r2, subset=['r2']).set_caption(\n",
    "        f'{target.upper()} Models - Sorted by RÂ²'\n",
    "    ).set_table_styles([\n",
    "        {'selector': 'caption', 'props': [('font-size', '16px'), ('font-weight', 'bold')]},\n",
    "        {'selector': 'th', 'props': [('background-color', '#4A90D9'), ('color', 'white')]},\n",
    "    ])\n",
    "    \n",
    "    return styled\n",
    "\n",
    "display(create_styled_table(df, 'valence'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556ba91e",
   "metadata": {},
   "source": [
    "---\n",
    "## âš¡ Energy Models (Intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979e1aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(create_styled_table(df, 'energy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b13c9b9",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ’ƒ Danceability Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3c7e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(create_styled_table(df, 'danceability'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50becc1c",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸŒŸ Popularity Models (Hardest Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273f1005",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(create_styled_table(df, 'popularity'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dccba25",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ“ˆ Visual Comparison: RÂ² Scores Across All Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbd7830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RÂ² comparison heatmap with enhanced academic styling\n",
    "pivot_r2 = df.pivot(index='model', columns='target', values='r2')\n",
    "pivot_r2 = pivot_r2[['valence', 'energy', 'danceability', 'popularity']]  # Order columns\n",
    "\n",
    "# Sort by average RÂ²\n",
    "pivot_r2['avg_r2'] = pivot_r2.mean(axis=1)\n",
    "pivot_r2 = pivot_r2.sort_values('avg_r2', ascending=False)\n",
    "pivot_r2 = pivot_r2.drop('avg_r2', axis=1)\n",
    "\n",
    "# Create heatmap with enhanced styling\n",
    "fig, ax = plt.subplots(figsize=(14, 16))\n",
    "sns.heatmap(pivot_r2, annot=True, fmt='.3f', cmap='RdYlGn', center=0.3,\n",
    "            linewidths=2, linecolor='white', ax=ax, vmin=-0.2, vmax=0.9,\n",
    "            cbar_kws={'label': 'RÂ² Score', 'shrink': 0.85},\n",
    "            annot_kws={'fontsize': 11, 'weight': 'bold'})\n",
    "ax.set_title('RÂ² Scores Heatmap', \n",
    "             fontsize=18, fontweight='bold', pad=25)\n",
    "ax.tick_params(axis='x', labelsize=14, width=1.5)\n",
    "ax.tick_params(axis='y', labelsize=13, width=1.5)\n",
    "plt.setp(ax.get_xticklabels(), fontweight='bold')\n",
    "plt.setp(ax.get_yticklabels(), fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/experiment2_r2_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: results/figures/experiment2_r2_heatmap.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c788cd",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ“Š Top 5 Models Bar Chart Per Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6c5fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "targets = ['valence', 'energy', 'danceability', 'popularity']\n",
    "colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D']\n",
    "\n",
    "for ax, target, color in zip(axes.flatten(), targets, colors):\n",
    "    top5 = df[df['target'] == target].nlargest(5, 'r2')\n",
    "    \n",
    "    bars = ax.barh(top5['model'], top5['r2'], color=color, edgecolor='black', alpha=0.85, linewidth=1.5)\n",
    "    ax.set_xlabel('RÂ² Score', fontsize=14, fontweight='bold', labelpad=8)\n",
    "    ax.set_title(f'{target.upper()}', fontsize=15, fontweight='bold', pad=15)\n",
    "    ax.set_xlim(0, max(top5['r2']) * 1.15)\n",
    "    ax.grid(True, alpha=0.3, axis='x', linestyle='--', linewidth=1.2)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(1.5)\n",
    "    ax.spines['bottom'].set_linewidth(1.5)\n",
    "    ax.tick_params(axis='both', width=1.2, labelsize=12)\n",
    "    \n",
    "    # Add value labels with bold font\n",
    "    for bar, val in zip(bars, top5['r2']):\n",
    "        ax.text(val + 0.01, bar.get_y() + bar.get_height()/2, f'{val:.3f}', \n",
    "                va='center', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    ax.invert_yaxis()\n",
    "    plt.setp(ax.get_yticklabels(), fontweight='bold', fontsize=12)\n",
    "\n",
    "plt.suptitle('Top 5 Models by RÂ² Score', \n",
    "             fontsize=17, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/experiment2_top5_models.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: results/figures/experiment2_top5_models.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f363538d",
   "metadata": {},
   "source": [
    "---\n",
    "## â±ï¸ Training Time Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34288640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate training time by model with enhanced styling\n",
    "time_by_model = df.groupby('model')['train_time_seconds'].mean().sort_values(ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(time_by_model)))\n",
    "bars = ax.barh(time_by_model.index, time_by_model.values, color=colors, \n",
    "               edgecolor='black', alpha=0.85, linewidth=1.5)\n",
    "ax.set_xlabel('Average Training Time (seconds)', fontsize=15, fontweight='bold', labelpad=10)\n",
    "ax.invert_yaxis()\n",
    "ax.grid(True, alpha=0.3, axis='x', linestyle='--', linewidth=1.2)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_linewidth(1.5)\n",
    "ax.spines['bottom'].set_linewidth(1.5)\n",
    "ax.tick_params(axis='both', width=1.2, labelsize=12)\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, time_by_model.values):\n",
    "    if val > 100:\n",
    "        label = f'{val/60:.1f}m'\n",
    "    else:\n",
    "        label = f'{val:.1f}s'\n",
    "    ax.text(val + 10, bar.get_y() + bar.get_height()/2, label, \n",
    "            va='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.setp(ax.get_yticklabels(), fontweight='bold', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/experiment2_training_time.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: results/figures/experiment2_training_time.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b272d19",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ“‰ RMSE Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1151ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RMSE comparison (lower is better) with enhanced styling\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "for ax, target, color in zip(axes.flatten(), targets, colors):\n",
    "    top5 = df[df['target'] == target].nsmallest(5, 'rmse')  # Smallest RMSE = best\n",
    "    \n",
    "    bars = ax.barh(top5['model'], top5['rmse'], color=color, edgecolor='black', \n",
    "                   alpha=0.85, linewidth=1.5)\n",
    "    ax.set_xlabel('RMSE', fontsize=14, fontweight='bold', labelpad=8)\n",
    "    ax.set_title(f'{target.upper()}', fontsize=15, fontweight='bold', pad=15)\n",
    "    ax.grid(True, alpha=0.3, axis='x', linestyle='--', linewidth=1.2)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(1.5)\n",
    "    ax.spines['bottom'].set_linewidth(1.5)\n",
    "    ax.tick_params(axis='both', width=1.2, labelsize=12)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, val in zip(bars, top5['rmse']):\n",
    "        ax.text(val + 0.001, bar.get_y() + bar.get_height()/2, f'{val:.4f}', \n",
    "                va='center', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    ax.invert_yaxis()\n",
    "    plt.setp(ax.get_yticklabels(), fontweight='bold', fontsize=12)\n",
    "\n",
    "plt.suptitle('Top 5 Models by RMSE', \n",
    "             fontsize=17, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/experiment2_top5_rmse.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: results/figures/experiment2_top5_rmse.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bde1e8",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ”¬ Default vs Tuned Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af62b994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare default vs tuned versions\n",
    "tuned_models = df[df['model'].str.contains('_tuned')].copy()\n",
    "tuned_models['base_model'] = tuned_models['model'].str.replace('_tuned', '')\n",
    "\n",
    "default_models = df[~df['model'].str.contains('_tuned') & ~df['model'].isin(['Mean'])].copy()\n",
    "default_models['base_model'] = default_models['model']\n",
    "\n",
    "# Merge to compare\n",
    "comparison = tuned_models.merge(\n",
    "    default_models[['target', 'base_model', 'r2', 'rmse']], \n",
    "    on=['target', 'base_model'], \n",
    "    suffixes=('_tuned', '_default')\n",
    ")\n",
    "comparison['r2_improvement'] = comparison['r2_tuned'] - comparison['r2_default']\n",
    "comparison['rmse_improvement'] = comparison['rmse_default'] - comparison['rmse_tuned']  # Positive = better\n",
    "\n",
    "# Display improvement summary\n",
    "improvement_summary = comparison.groupby('base_model').agg({\n",
    "    'r2_improvement': 'mean',\n",
    "    'rmse_improvement': 'mean'\n",
    "}).sort_values('r2_improvement', ascending=False)\n",
    "\n",
    "print(\"Tuning Impact (Average across all targets):\")\n",
    "print(\"=\"*50)\n",
    "styled_improvement = improvement_summary.style.format({\n",
    "    'r2_improvement': '{:+.4f}',\n",
    "    'rmse_improvement': '{:+.4f}'\n",
    "}).background_gradient(cmap='RdYlGn', subset=['r2_improvement']).set_caption(\n",
    "    'Tuning Impact: Positive = Improvement'\n",
    ")\n",
    "display(styled_improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a333cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize tuning impact with enhanced styling\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "x = np.arange(len(improvement_summary))\n",
    "width = 0.6\n",
    "\n",
    "bars = ax.bar(x, improvement_summary['r2_improvement'], width, \n",
    "              color=['#90EE90' if v > 0 else '#FF6B6B' for v in improvement_summary['r2_improvement']],\n",
    "              edgecolor='black', alpha=0.85, linewidth=1.5)\n",
    "\n",
    "ax.set_ylabel('RÂ² Improvement', fontsize=15, fontweight='bold', labelpad=10)\n",
    "ax.set_title(' Hyperparameter Tuning Impact on RÂ²', \n",
    "             fontsize=17, fontweight='bold', pad=20)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(improvement_summary.index, rotation=45, ha='right', fontweight='bold', fontsize=12)\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=2)\n",
    "ax.grid(True, alpha=0.3, axis='y', linestyle='--', linewidth=1.2)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_linewidth(1.5)\n",
    "ax.spines['bottom'].set_linewidth(1.5)\n",
    "ax.tick_params(axis='both', width=1.2, labelsize=12)\n",
    "\n",
    "# Add value labels with enhanced visibility\n",
    "for bar, val in zip(bars, improvement_summary['r2_improvement']):\n",
    "    y_pos = val + 0.003 if val >= 0 else val - 0.012\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, y_pos, f'{val:+.3f}', \n",
    "            ha='center', va='bottom' if val >= 0 else 'top', \n",
    "            fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/experiment2_tuning_impact.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: results/figures/experiment2_tuning_impact.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1575835",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ“‹ Complete Results Table (All Models, All Targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e922498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive table\n",
    "full_table = df[['target', 'model', 'r2', 'rmse', 'mae', 'explained_variance', \n",
    "                 'pred_mean', 'pred_std', 'residual_mean', 'residual_std', 'train_time_seconds']].copy()\n",
    "full_table = full_table.sort_values(['target', 'r2'], ascending=[True, False])\n",
    "\n",
    "def color_by_target(val):\n",
    "    colors = {\n",
    "        'valence': 'background-color: #E8F4FD',\n",
    "        'energy': 'background-color: #FDF4E8',\n",
    "        'danceability': 'background-color: #F4E8FD',\n",
    "        'popularity': 'background-color: #E8FDF4'\n",
    "    }\n",
    "    return colors.get(val, '')\n",
    "\n",
    "styled_full = full_table.style.format({\n",
    "    'r2': '{:.4f}',\n",
    "    'rmse': '{:.4f}',\n",
    "    'mae': '{:.4f}',\n",
    "    'explained_variance': '{:.4f}',\n",
    "    'pred_mean': '{:.4f}',\n",
    "    'pred_std': '{:.4f}',\n",
    "    'residual_mean': '{:.4f}',\n",
    "    'residual_std': '{:.4f}',\n",
    "    'train_time_seconds': '{:.1f}'\n",
    "}).applymap(color_by_target, subset=['target']).set_caption(\n",
    "    'Complete Results - All Models, All Targets'\n",
    ").set_table_styles([\n",
    "    {'selector': 'caption', 'props': [('font-size', '16px'), ('font-weight', 'bold')]},\n",
    "    {'selector': 'th', 'props': [('background-color', '#2E86AB'), ('color', 'white')]},\n",
    "])\n",
    "\n",
    "display(styled_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92eae2e",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸŽ¯ Final Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07052be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 2 models per target\n",
    "recommendations = []\n",
    "for target in targets:\n",
    "    top2 = df[df['target'] == target].nlargest(2, 'r2')[['target', 'model', 'r2', 'rmse', 'train_time_seconds']]\n",
    "    top2['recommendation'] = ['ðŸ¥‡ Primary', 'ðŸ¥ˆ Backup']\n",
    "    recommendations.append(top2)\n",
    "\n",
    "rec_df = pd.concat(recommendations)\n",
    "\n",
    "styled_rec = rec_df.style.format({\n",
    "    'r2': '{:.4f}',\n",
    "    'rmse': '{:.4f}',\n",
    "    'train_time_seconds': '{:.1f}s'\n",
    "}).set_caption('Final Model Recommendations for Test Evaluation').set_table_styles([\n",
    "    {'selector': 'caption', 'props': [('font-size', '18px'), ('font-weight', 'bold'), ('color', '#2E86AB')]},\n",
    "    {'selector': 'th', 'props': [('background-color', '#2E86AB'), ('color', 'white')]},\n",
    "])\n",
    "\n",
    "display(styled_rec)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "for target in targets:\n",
    "    best = df[df['target'] == target].nlargest(1, 'r2').iloc[0]\n",
    "    print(f\"\\n{target.upper()}:\")\n",
    "    print(f\"  Best Model: {best['model']}\")\n",
    "    print(f\"  RÂ² = {best['r2']:.4f} | RMSE = {best['rmse']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
